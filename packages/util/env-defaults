# Default Harmony Environment Variables - do not edit this file locally.
# Override any of the values here by setting a value in a .env file at the
# root level of this repository. All of the default values in this file
# should work for developing locally on Mac OS X.

###########################################################################
#                             General Config                              #
#                                                                         #
# Settings to control how Harmony behaves                                 #
###########################################################################

# The port on which to run the Harmony backend that receives service
# callbacks
BACKEND_PORT=3001

# The port on which to run a given service
PORT=5000

# The base URL for the service callbacks. This needs to be accessible from
# wherever the service is run. The Harmony CI/CD scripts sets this to the
# backend load balancer when running on AWS. The default is set for
# running Harmony in Kubernetes.
CALLBACK_URL_ROOT=http://harmony:3001
# When running locally on a Mac or Linux (not in Kubernetes), use the appropriate value below.
# Mac OS X:
# CALLBACK_URL_ROOT=http://host.docker.internal:3001
# Linux:
# CALLBACK_URL_ROOT=http://localhost:3001

# The CMR Endpoint to use (e.g. URL for local, SIT, UAT, or production)
CMR_ENDPOINT=https://cmr.uat.earthdata.nasa.gov

# The Metrics Endpoint (Kibana) to use (linked to from the Workflow UI)
METRICS_ENDPOINT=

# The Metrics index to query (via the METRICS_ENDPOINT)
METRICS_INDEX=

# For testing: Whether to use Localstack instead of AWS S3.  Options are "true" or "false".
USE_LOCALSTACK=true

# Hostname for harmony to use to connect to Localstack
LOCALSTACK_HOST=localstack

# Identifier so backends know which Harmony client submitted the request
CLIENT_ID=harmony-unknown

# When set to true log messages are logged as a text string instead of the default
# JSON format. Useful when running harmony locally and viewing logs via a terminal.
TEXT_LOGGER=true

# When set to true log all database queries performed by knex
DEBUG_KNEX=false

# Log level (error, warn, info, debug)
LOG_LEVEL=debug

# Default number of results in a page
DEFAULT_RESULT_PAGE_SIZE=2000

# The maximum allowed granules in any request synchronous or asynchronous. If a service
# attempts to configure a value greater than this limit for either maximum_async_granules
# or maximum_async_granules we will override the configuration to limit to this value.
MAX_GRANULE_LIMIT=10000000

# max JSON payload that can be sent to query-cmr via express. Should take the form of '100mb', etc.
MAX_QUERY_CMR_JSON_SIZE=400mb

# String to identify the type of environment.  Options:
#  - "development" for local development.
#  - "production" for deployments with a separate postgres server (SIT, UAT, Production).
#  - "test" for unit / integration tests
# This is a conventional identifier to switch application behavior
NODE_ENV=development

# String to identify which database engine to use. Options:
#  - "postgres"
#  - "sqlite"
# Note that sqlite is only used for running tests
DATABASE_TYPE=postgres

# Connection string to use to connect to the database.  Used for
# DATABASE_TYPE="postgres" databases.  For tests this is
# ignored, using a sqlite3 file instead
DATABASE_URL=postgresql://postgres:password@localhost:5432/postgres

# Whether or not to use queues for retrieving work-items when handling polling for work
USE_SERVICE_QUEUES=true

# SQS queue used to request scheduling of work items for a service
WORK_ITEM_SCHEDULER_QUEUE_URL=http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/work-item-scheduler-queue

# SQS queue used to process work item updates
WORK_ITEM_UPDATE_QUEUE_URL=http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/work-item-update-queue.fifo

# SQS queue used to process work item updates
LARGE_WORK_ITEM_UPDATE_QUEUE_URL=http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/large-work-item-update-queue.fifo

# maximum number of items to pull from the queue at once for the large item queue (to avoid visibility timeouts)
# if this is set to greater than 10 (the SQS max) then 10 will be used instead
LARGE_WORK_ITEM_UPDATE_QUEUE_MAX_BATCH_SIZE=2

# An IAM role that allows access to a bucket and prefix where outputs for asynchronous
# requests are stored by backend services.
SAME_REGION_ACCESS_ROLE=same-region-access-role

# Long polling wait time (in seconds) for queues
QUEUE_LONG_POLLING_WAIT_TIME_SEC=20

GIOVANNI_AVERAGING_SERVICES_ADAPTER_SERVICE_QUEUE_URLS='["giovanni-averaging-adapter:1.0.0,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/giovanni-averaging-services-adapter.fifo"]'
GEOLOCO_SERVICE_QUEUE_URLS='["ldds/geoloco:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/geoloco.fifo"]'
SUBSET_BAND_NAME_SERVICE_QUEUE_URLS='["ldds/subset-band-name:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/subset-band-name.fifo"]'
GIOVANNI_TIME_SERIES_ADAPTER_SERVICE_QUEUE_URLS='["giovanni-time-series-adapter:1.0.0,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/giovanni-time-series-adapter.fifo"]'
HARMONY_GDAL_ADAPTER_SERVICE_QUEUE_URLS='["ghcr.io/nasa/harmony-gdal-adapter:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/harmony-gdal-adapter.fifo"]'
HYBIG_SERVICE_QUEUE_URLS='["ghcr.io/nasa/harmony-browse-image-generator:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/hybig.fifo"]'
HARMONY_SERVICE_EXAMPLE_SERVICE_QUEUE_URLS='["harmonyservices/service-example:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/harmony-service-example.fifo"]'
HARMONY_REGRIDDER_SERVICE_QUEUE_URLS='["ghcr.io/nasa/harmony-regridding-service:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/harmony-regridder.fifo"]'
SMAP_L2_GRIDDER_SERVICE_QUEUE_URLS='["ghcr.io/nasa/harmony-smap-l2-gridder:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/harmony-smap-l2-gridder.fifo"]'
SWATH_PROJECTOR_SERVICE_QUEUE_URLS='["ghcr.io/nasa/harmony-swath-projector:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/swath-projector.fifo"]'
HOSS_SERVICE_QUEUE_URLS='["ghcr.io/nasa/harmony-opendap-subsetter:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/hoss.fifo"]'
MASKFILL_SERVICE_QUEUE_URLS='["ghcr.io/nasa/harmony-maskfill:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/maskfill.fifo"]'
TRAJECTORY_SUBSETTER_SERVICE_QUEUE_URLS='["ghcr.io/nasa/harmony-trajectory-subsetter:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/trajectory-subsetter.fifo"]'
PODAAC_CONCISE_SERVICE_QUEUE_URLS='["ghcr.io/podaac/concise:sit,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/podaac-concise.fifo"]'
PODAAC_L2_SUBSETTER_SERVICE_QUEUE_URLS='["ghcr.io/podaac/l2ss-py:sit,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/podaac-l2-subsetter.fifo"]'
PODAAC_PS3_SERVICE_QUEUE_URLS='["podaac/podaac-cloud/podaac-shapefile-subsetter:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/podaac-shapefile-subsetter.fifo"]'
PODAAC_NETCDF_CONVERTER_SERVICE_QUEUE_URLS='["podaac/podaac-cloud/podaac-netcdf-converter:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/podaac-netcdf-converter.fifo"]'
QUERY_CMR_SERVICE_QUEUE_URLS='["harmonyservices/query-cmr:stable,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/query-cmr.fifo"]'
BATCHEE_SERVICE_QUEUE_URLS='["ghcr.io/nasa/batchee:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/batchee.fifo"]'
STITCHEE_SERVICE_QUEUE_URLS='["ghcr.io/nasa/stitchee:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/stitchee.fifo"]'
FILTERING_SERVICE_QUEUE_URLS='["harmony/filtering:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/filtering.fifo"]'
HARMONY_METADATA_ANNOTATOR_SERVICE_QUEUE_URLS='["ghcr.io/nasa/harmony-metadata-annotator:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/harmony-metadata-annotator.fifo"]'
CASPER_SERVICE_QUEUE_URLS='["ghcr.io/nasa/harmony-casper:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/casper.fifo"]'

# The number of seconds to allow a pod to continue processing an active request before terminating a pod
DEFAULT_POD_GRACE_PERIOD_SECS=14400

# page size to use with CMR calls
CMR_MAX_PAGE_SIZE=2000

# Prefix before "harmonyservices/task-name" for built-in tasks like query-cmr, e.g. an ECR location
# If not blank, it should end in a slash if there is a slash before "harmony"
BUILT_IN_TASK_PREFIX=
# Version to use for all built-in tasks.  "latest" (local / sandbox), "sit", "uat", or "prod"
BUILT_IN_TASK_VERSION=latest

# AWS region where harmony is deployed, irrelevant for local development
AWS_DEFAULT_REGION=us-west-2

# The bucket where final service output data will be staged
# Default: A bucket created for use in localstack
STAGING_BUCKET=local-staging-bucket

# The bucket where intermediate service artifacts and STAC catalogs will be staged
# Default: A bucket created for use in localstack
ARTIFACT_BUCKET=local-artifact-bucket

# The DNS entry to use for the host exposing the Harmony back end API for callbacks. This
# default is appropriate for when Harmony is running in Kubernetes.
BACKEND_HOST=harmony
#  For local development outside of Kubernetes:
# Mac OS X:
# BACKEND_HOST=host.docker.internal
# Linux:
# BACKEND_HOST=localhost

# If a retryable error is encountered while attempting to update a work item,
# the HTTP client will retry a maximum of this many times.
# MAX_PUT_WORK_RETRIES should be high enough to allow a work item update to succeed
# even when a deployment is happening (~25 min max currently)
MAX_PUT_WORK_RETRIES=30

# Maximum size (in bytes) of the token cache, 50MB
TOKEN_CACHE_SIZE=50000000

# Token Cache TTL in milliseconds
TOKEN_CACHE_TTL=300000

# Maximum size (in bytes) of the cache for EDL searches, 50MB
EDL_CACHE_SIZE=50000000

# EDL Cache TTL in milliseconds
EDL_CACHE_TTL=600000

# Maximum size (in bytes) of the cache for CMR searches, 256MB
CMR_CACHE_SIZE=256000000

# CMR Cache TTL in milliseconds
CMR_CACHE_TTL=600000
