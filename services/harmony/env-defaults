# Default Harmony Environment Variables - do not edit this file locally.
# Override any of the values here by setting a value in a .env file at the
# root level of this repository. All of the default values in this file
# should work for developing locally on Mac OS X.

###########################################################################
#                             No defaults possible                        #
#                                                                         #
# Parameters must be overridden, no default value can be provided         #
###########################################################################

# Random string used to sign cookies that should be consistent between
# load-balanced instances of Harmony.  You can use
# `hexdump -n 128 -e '"%08x"' /dev/random`
# to generate a 128 byte random hex string (256 chars)
COOKIE_SECRET=

# Random string used for encrypting and decrypting Earthdata login tokens
# sent to backend services
# `hexdump -n 32 -e '"%08x"' /dev/random`
# to generate a 32 character random string
SHARED_SECRET_KEY=

###########################################################################
#                             General Config                              #
#                                                                         #
# Settings to control how Harmony behaves                                 #
###########################################################################

# The host network interface to bind against. Set to 127.0.0.1 to limit to
# only on the localhost when running locally
HOST_BINDING='0.0.0.0'

# The port on which to run the Harmony frontend
PORT=3000

# The Metrics Endpoint (Kibana) to use (linked to from the Workflow UI)
METRICS_ENDPOINT=

# The Metrics index to query (via the METRICS_ENDPOINT)
METRICS_INDEX=

# If set to true the listener for the harmony application will use HTTPS
USE_HTTPS=false

# Whether to run example service endpoints under /example.  Useful for
# testing HTTP backends without actual service calls.  See example/http-service.js
EXAMPLE_SERVICES=true

# Log level (error, warn, info, debug)
LOG_LEVEL=debug

# Default number of results in a page
DEFAULT_RESULT_PAGE_SIZE=2000

# Default number of jobs listed in a page
DEFAULT_JOB_LIST_PAGE_SIZE=10

# TODO change this to a smaller number when aggregating services are updated to handle paged catalogs
# See HARMONY-1178
AGGREGATE_STAC_CATALOG_MAX_PAGE_SIZE=1000000

# Maximum number of results in a page
MAX_PAGE_SIZE=2000

# Number of granules allowed for a synchronous request. When the request exceeds
# this number it will be processed asynchronously. If a service provides a
# value in services-uat.yml or services-prod.yml for maximum_sync_granules it will override this value.
MAX_SYNCHRONOUS_GRANULES=1

# The threshold of the number of granules in a request that will trigger auto-pausing with preview
PREVIEW_THRESHOLD=100

# The maximum number of errors to allow for a job before considering it failed
MAX_ERRORS_FOR_JOB=2000

# The minimum number of work-items that must be in the successful or failed state before we start
# testing for job failure based on failure percentage
MIN_DONE_ITEMS_FOR_FAIL_CHECK=10

# The maximum percentage of failed work-items to allow for a job before considering it failed
MAX_PERCENT_ERRORS_FOR_JOB=75

# max JSON payload that can be sent to the harmony back end via express. Should take the form of '100mb', etc.
MAX_HARMONY_BACK_END_JSON_SIZE=400mb

# A bucket with brief lifecycle where temporary uploads (shapefiles) are stored while
# requests are in flight
UPLOAD_BUCKET=local-upload-bucket

# The EDL Group ID for the group whose users can access the admin interface
ADMIN_GROUP_ID=9b359064-287f-411f-b2cc-ed4429676900

# The EDL Group ID for the group whose users can access logs in the workflow-ui for their own jobs or shareable jobs
LOG_VIEWER_GROUP_ID=0cf2a427-96cc-453e-ae44-e28dd0958738

# The EDL Group ID for the group whose users can deploy backend services
SERVICE_DEPLOYER_GROUP_ID=e0f5c59f-ee8b-49e0-b23d-587f15e56441

# This EDL Group ID allows the user to perform actions like changing log level and enabling service deployments
CORE_PERMISSIONS_GROUP_ID=1759aff6-70f4-426c-b5c3-319c8ab6e870

# The number of ms to wait between polling to check whether a synchronous request completed
SYNC_REQUEST_POLL_INTERVAL_MS=100

# Number of times to retry a failed work item
WORK_ITEM_RETRY_LIMIT=5

# The maximum number of input granules in each invocation of a service
MAX_BATCH_INPUTS=1000000000000

# The upper limit on the combined sizes of all the files in a batch
MAX_BATCH_SIZE_IN_BYTES=5000000000

# Bamboo release
RELEASE_VERSION=0.0.0

# Client ID passed in as a header when making calls to other APIs
CLIENT_ID=harmony-local

# Identifies the harmony user agent when harmony makes calls to other APIs
USER_AGENT="harmony/0.0.0 harmony-local"

# The node environment (production, test, development)
NODE_ENV=production

# The object store used for storing shapefiles. Only S3 is supported currently.
OBJECT_STORE_TYPE=s3

# Maximum number of non-file fields to accept when providing a shapefile to harmony
MAX_POST_FIELDS=100

# Maximum size (in bytes) for shapefiles
MAX_POST_FILE_SIZE=2000000000

# Maximum number of multipart parts to accept when providing a shapefile
MAX_POST_FILE_PARTS=100

# Maximum size (in bytes) of the cache for data operations, 512MB
MAX_DATA_OPERATION_CACHE_SIZE=512000000

# WKT POINT/LINESTRING to POLYGON conversion side length, 0.0001 is about 11 meters in precision
WKT_PRECISION=0.0001

# Maximum number of sides for a polygon created from a geojson Point with radius
MAX_POINT_CIRCLE_SIDES=100

# The base of the exponential function used to calculate the number of sides a polygon should
# have to approximate the circle around a point with a given radius
# Must be greater than zero and less than one
POINT_CIRCLE_FUNCTION_BASE=0.99999

# Comma-separated list of label values that are explicitly allowed
LABELS_ALLOW_LIST=
# Comma-separated list of label values that are explicitly forbidden, with the first one just
# for demo purposes
LABELS_FORBID_LIST=this_is_a_forbidden_label
# The max number of labels to retrieve to populate label filter auto-complete
LABEL_FILTER_COMPLETION_COUNT=10

# Maximum size (in bytes) of the provider cache, 5MB
PROVIDER_CACHE_SIZE=5000000

# Provider Cache TTL in milliseconds, 1 hour
PROVIDER_CACHE_TTL=3600000

# Maximum size (in bytes) of the job status cache, 50MB
JOB_STATUS_CACHE_SIZE=50000000

# Job status cache TTL in milliseconds, 5 seconds
JOB_STATUS_CACHE_TTL=5000

#############################################################################
#                        OAuth 2 (Earthdata Login)                          #
#                                                                           #
# Variables used to configure OAuth 2 authentication for Harmony data users #
#                                                                           #
# To use Earthdata Login, you must first set up a new application using the #
# Earthdata Login UI.                                                       #
# https://wiki.earthdata.nasa.gov/display/EL/How+To+Register+An+Application #
#############################################################################

# Variable            Description                 Example
#--------------------------------------------------------------------------------------
# OAUTH_CLIENT_ID     EDL App Client ID           rCjHBluumLhppiIX5iZxoQ
# OAUTH_UID           EDL App UID                 harmony_kbeam
# OAUTH_PASSWORD      EDL App Password            top_secret
# OAUTH_REDIRECT_URI  Valid EDL App Redirect URL  http://localhost:3000/oauth2/redirect
# OAUTH_HOST          Earthdata Login URL         https://uat.urs.earthdata.nasa.gov

# Notes:
# The OAUTH_REDIRECT_URI needs to be provided verbatim when setting up the
# Earthdata Login app. Each EDL app has a list of valid Redirect URLs, and
# Harmony requires a URI endpoint of "/oauth2/redirect" for all environments.
# When running Harmony locally, for example, add a Redirect URL of
# `http://localhost:3000/oauth2/redirect`. Use HTTPS for non-local instances.
#
# The OAUTH_HOST is used by the Harmony API as well as Harmony services.
# This should be the same EDL environment as used by backend data sources.
# For example, if OAUTH_HOST points to UAT EDL, downloading data from a
# TEA endpoint that's integrated with PROD EDL will fail.

# Setting USE_EDL_CLIENT_APP to false and setting an EDL_TOKEN will prevent making
# use of any Earthdata login API calls and instead pass that EDL_TOKEN to CMR and
# backend service downloads. By bypassing EDL all admin features in harmony will be
# disabled since harmony will not authenticate with EDL using a client app.

USE_EDL_CLIENT_APP=true
EDL_TOKEN=

OAUTH_CLIENT_ID=
OAUTH_UID=
OAUTH_PASSWORD=

OAUTH_REDIRECT_URI=http://localhost:3000/oauth2/redirect
OAUTH_HOST=https://uat.urs.earthdata.nasa.gov

###########################################################################
#                               Test Suite                                #
#                                                                         #
# Settings for altering the behavior of the test suite that are not used  #
# elsewhere in the application.                                           #
###########################################################################

# How to handle fixtures for remote calls in the test suite:
#   record (default): Perform and record new calls.  Replay existing calls.
#   bloody: Perform and record all calls.  Never play back.
#   replay: Always play back.  Throw an error if a call is not recorded.
#   cheat: Play back cached calls.  Perform and do not cache any new calls
REPLAY=record

# True if server logs should be allowed to go to STDOUT.  When false
# (default), they are routed to logs/test.log and suppressed in STDOUT
LOG_STDOUT=false

# The services to deploy locally. A comma-separated list of services that the bin/deploy-services
# script should attempt to deploy. By default only a couple of harmony example services are deployed.
# When specifying another service to be deployed make sure the name matches the lower and dash case
# prefix for the image variable name. For example to deploy the harmony service example image which
# has a variable name of HARMONY_SERVICE_EXAMPLE_IMAGE you would specify harmony-service-example
# (converting to lowercase, converting to dash case, and dropping _IMAGE). Make sure if the image
# for the service is not publicly available that you have built the docker image locally, otherwise
# the service will fail to start.
LOCALLY_DEPLOYED_SERVICES=harmony-service-example

# Local development: Use the following to set the Kubernetes context used by start scripts
# minikube users should set it to "minikube"
KUBE_CONTEXT=docker-desktop

# Number of times to retry failed HTTP (408, 502, 503, 504) data download calls
# via the http module of the service library.

# backoff seconds = {backoff factor} * (2 ** ({retry number} - 1))
# where {retry number} = 1, 2, 3, ..., total_retries

# With a backoff_factor of 2 (the current default) and 10 retries,
# the total sleep seconds between executions will be:
# [0, 4, 8, 16, 32, 64, 120, 120, 120, 120] (~10 minutes)
# 120 seconds is the maximum backoff and there is always 0 seconds before the
# first retry regardless of the parameters.
MAX_DOWNLOAD_RETRIES=3

# The number of seconds to allow a pod to continue processing an active request before terminating a pod
DEFAULT_POD_GRACE_PERIOD_SECS=14400

# Hostname for k8s services to use to connect to Localstack - this is only used by the
# script that creates the env var config map for local development
LOCALSTACK_K8S_HOST=localstack

###########################################################################
#                            Feature Toggles                              #
###########################################################################

# Toggle whether the labeling dropdown should be enabled in the workflow ui
UI_LABELING=true

# Toggle whether users can explicitly choose the service chain to call for
# their request using the serviceId query parameter
ALLOW_SERVICE_SELECTION=true

# Whether to use clustering to fork one harmony process per available CPU
USE_CLUSTERING=false

###########################################################################
#                             Prometheus Config                           #
#                                                                         #
# This section is irrelevant for local development unless you are a       #
# harmony core developer who plans to deploy Prometheus locally           #
###########################################################################

# For Prometheus time variables, "m" postfix means "minutes".
# https://prometheus.io/docs/prometheus/latest/querying/basics/#time-durations
# For k8s CPU or memory variables, see this link for unit explanations:
# https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#meaning-of-cpu

# Prometheus deployment variables
PROMETHEUS_REQUESTS_CPU=128m
PROMETHEUS_REQUESTS_MEMORY=150Mi
PROMETHEUS_REQUESTS_EPHEMERAL_STORAGE=600Mi
PROMETHEUS_LIMITS_CPU=128m

PROMETHEUS_LIMITS_MEMORY=600Mi
PROMETHEUS_LIMITS_EPHEMERAL_STORAGE=2000Mi
PROMETHEUS_PROMETHEUS_SCRAPE_INTERVAL=15s
PROMETHEUS_POD_MANAGER_SCRAPE_INTERVAL=15s

# See https://prometheus.io/docs/prometheus/latest/storage/ for details on retention metrics.
# How long to keep prometheus metrics before cleaning up
PROMETHEUS_RETENTION_TIME=180d
# Maximum amount of space to use for Prometheus metrics before deleting oldest metrics
# Be sure to set this value to less than PROMETHEUS_LIMITS_EPHEMERAL_STORAGE otherwise the
# pod may be evicted due to running out of ephemeral space.
PROMETHEUS_RETENTION_SIZE=1750MB

# how many consecutive minutes to sample in the PromQL query for KubernetesPodNotHealthy
PROMETHEUS_POD_NOT_HEALTHY_DURATION=10m
PROMETHEUS_PENDING_POD_NOT_HEALTHY_DURATION=15m

# how long the specified alert must be firing before being sent to the Alert Manager
PROMETHEUS_POD_NOT_HEALTHY_WAIT_FOR=5m
PROMETHEUS_NODE_NOT_READY_WAIT_FOR=10m
PROMETHEUS_PENDING_POD_NOT_HEALTHY_WAIT_FOR=45m

# Alert manager variables (irrelevant to local development).
# To see/test whether alerts are firing locally, kubectl port-forward {prometheus-pod} 9090:9090 -n monitoring
# and navigate to the prometheus UI http://localhost:9090/alerts
ALERT_MANAGER_REQUESTS_CPU=500m
ALERT_MANAGER_REQUESTS_MEMORY=500M
ALERT_MANAGER_LIMITS_CPU=1
ALERT_MANAGER_LIMITS_MEMORY=1Gi

ALERT_MANAGER_TOPIC_ARN=

###########################################################################
#             Horizontal Pod Autoscaling Config                           #
#                                                                         #
# Variables that are used to configure scaling for service pods           #
#                                                                         #
###########################################################################

HPA_MIN_REPLICAS=1
HPA_MAX_REPLICAS=10

# See https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/quantity/#Quantity
# for an explanation of the "m" suffix (e.g. 10 will be serialized as "10000m").
# With this value, the HPAs (when deployed) will try to ensure a pod exists for every 10 queued work items.
HPA_TARGET_VALUE=10000m

###########################################################################
#                             Service Config                              #
#                                                                         #
#  Variables that control pod setup for services                          #
###########################################################################

# The port on which a worker container listens for work from the manager container
WORKER_PORT=5001

# The number of work scheduler pods to run
SCHEDULER_POD_REPLICAS=1

# The number of update queue processors to run for the large work-item queue
LARGE_WORK_UPDATER_POD_REPLICAS=1

# The number of update queue processors to run for the small work-item queue
SMALL_WORK_UPDATER_POD_REPLICAS=1

# The number of work failer pods to run
WORK_FAILER_POD_REPLICAS=1

# harmony image only used for dev
HARMONY_IMAGE=harmonyservices/harmony:stable

# The service runner image used as a sidecar for polling for work for
SERVICE_RUNNER_REQUESTS_CPU=128m
SERVICE_RUNNER_REQUESTS_MEMORY=128Mi
SERVICE_RUNNER_LIMITS_CPU=1024m
SERVICE_RUNNER_LIMITS_MEMORY=512Mi
SERVICE_RUNNER_IMAGE=harmonyservices/service-runner:stable

# work scheduler
WORK_ITEM_SCHEDULER_REQUESTS_CPU=128m
WORK_ITEM_SCHEDULER_REQUESTS_MEMORY=128Mi
WORK_ITEM_SCHEDULER_LIMITS_CPU=1024m
WORK_ITEM_SCHEDULER_LIMITS_MEMORY=512Mi
WORK_ITEM_SCHEDULER_IMAGE=harmonyservices/work-scheduler:stable

# work updater
WORK_ITEM_UPDATER_REQUESTS_CPU=128m
WORK_ITEM_UPDATER_REQUESTS_MEMORY=128Mi
WORK_ITEM_UPDATER_LIMITS_CPU=1024m
WORK_ITEM_UPDATER_LIMITS_MEMORY=512Mi
WORK_ITEM_UPDATER_IMAGE=harmonyservices/work-updater:stable

# cron service
CRON_SERVICE_REQUESTS_CPU=128m
CRON_SERVICE_REQUESTS_MEMORY=128Mi
CRON_SERVICE_LIMITS_CPU=512m
CRON_SERVICE_LIMITS_MEMORY=512Mi
CRON_SERVICE_IMAGE=harmonyservices/cron-service:stable

# work failer
WORK_FAILER_REQUESTS_CPU=128m
WORK_FAILER_REQUESTS_MEMORY=128Mi
WORK_FAILER_LIMITS_CPU=512m
WORK_FAILER_LIMITS_MEMORY=512Mi
WORK_FAILER_IMAGE=harmonyservices/work-failer:stable

# backend services
HARMONY_GDAL_ADAPTER_IMAGE=ghcr.io/nasa/harmony-gdal-adapter:latest
HARMONY_GDAL_ADAPTER_REQUESTS_CPU=128m
HARMONY_GDAL_ADAPTER_REQUESTS_MEMORY=128Mi
HARMONY_GDAL_ADAPTER_LIMITS_CPU=128m
HARMONY_GDAL_ADAPTER_LIMITS_MEMORY=8Gi
HARMONY_GDAL_ADAPTER_INVOCATION_ARGS='python -m gdal_subsetter'

HYBIG_IMAGE=ghcr.io/nasa/harmony-browse-image-generator:latest
HYBIG_REQUESTS_CPU=128m
HYBIG_REQUESTS_MEMORY=128Mi
HYBIG_LIMITS_CPU=128m
HYBIG_LIMITS_MEMORY=8Gi
HYBIG_INVOCATION_ARGS='python -m harmony_service'

HARMONY_SERVICE_EXAMPLE_IMAGE=harmonyservices/service-example:latest
HARMONY_SERVICE_EXAMPLE_REQUESTS_CPU=128m
HARMONY_SERVICE_EXAMPLE_REQUESTS_MEMORY=128Mi
HARMONY_SERVICE_EXAMPLE_LIMITS_CPU=128m
HARMONY_SERVICE_EXAMPLE_LIMITS_MEMORY=512Mi
HARMONY_SERVICE_EXAMPLE_INVOCATION_ARGS='python -m harmony_service_example'

HARMONY_REGRIDDER_IMAGE=ghcr.io/nasa/harmony-regridding-service:latest
HARMONY_REGRIDDER_REQUESTS_CPU=128m
HARMONY_REGRIDDER_REQUESTS_MEMORY=128Mi
HARMONY_REGRIDDER_LIMITS_CPU=128m
HARMONY_REGRIDDER_LIMITS_MEMORY=4096Mi
HARMONY_REGRIDDER_INVOCATION_ARGS='python -m harmony_regridding_service'

SWATH_PROJECTOR_IMAGE=ghcr.io/nasa/harmony-swath-projector:latest
SWATH_PROJECTOR_REQUESTS_CPU=128m
SWATH_PROJECTOR_REQUESTS_MEMORY=128Mi
SWATH_PROJECTOR_LIMITS_CPU=128m
SWATH_PROJECTOR_LIMITS_MEMORY=512Mi
SWATH_PROJECTOR_INVOCATION_ARGS='python -m swath_projector'

HOSS_IMAGE=ghcr.io/nasa/harmony-opendap-subsetter:latest
HOSS_REQUESTS_CPU=128m
HOSS_REQUESTS_MEMORY=128Mi
HOSS_LIMITS_CPU=128m
HOSS_LIMITS_MEMORY=8Gi
HOSS_INVOCATION_ARGS='python -m hoss'

MASKFILL_IMAGE=ghcr.io/nasa/harmony-maskfill:latest
MASKFILL_REQUESTS_CPU=128m
MASKFILL_REQUESTS_MEMORY=128Mi
MASKFILL_LIMITS_CPU=128m
MASKFILL_LIMITS_MEMORY=8Gi
MASKFILL_INVOCATION_ARGS='python -m maskfill'

TRAJECTORY_SUBSETTER_IMAGE=sds/trajectory-subsetter:latest
TRAJECTORY_SUBSETTER_REQUESTS_CPU=128m
TRAJECTORY_SUBSETTER_REQUESTS_MEMORY=128Mi
TRAJECTORY_SUBSETTER_LIMITS_CPU=128m
TRAJECTORY_SUBSETTER_LIMITS_MEMORY=8Gi
TRAJECTORY_SUBSETTER_INVOCATION_ARGS='python harmony_service/adapter.py'

PODAAC_CONCISE_IMAGE=ghcr.io/podaac/concise:sit
PODAAC_CONCISE_REQUESTS_CPU=128m
PODAAC_CONCISE_REQUESTS_MEMORY=128Mi
PODAAC_CONCISE_LIMITS_CPU=128m
PODAAC_CONCISE_LIMITS_MEMORY=2Gi
PODAAC_CONCISE_INVOCATION_ARGS='concise_harmony'

PODAAC_L2_SUBSETTER_IMAGE=ghcr.io/podaac/l2ss-py:sit
PODAAC_L2_SUBSETTER_REQUESTS_CPU=128m
PODAAC_L2_SUBSETTER_REQUESTS_MEMORY=128Mi
PODAAC_L2_SUBSETTER_LIMITS_CPU=128m
PODAAC_L2_SUBSETTER_LIMITS_MEMORY=512Mi
PODAAC_L2_SUBSETTER_INVOCATION_ARGS='./docker-entrypoint.sh'

PODAAC_PS3_IMAGE=podaac/podaac-cloud/podaac-shapefile-subsetter:latest
PODAAC_PS3_REQUESTS_CPU=128m
PODAAC_PS3_REQUESTS_MEMORY=128Mi
PODAAC_PS3_LIMITS_CPU=128m
PODAAC_PS3_LIMITS_MEMORY=512Mi

PODAAC_NETCDF_CONVERTER_IMAGE=podaac/podaac-cloud/podaac-netcdf-converter:latest
PODAAC_NETCDF_CONVERTER_REQUESTS_CPU=128m
PODAAC_NETCDF_CONVERTER_REQUESTS_MEMORY=128Mi
PODAAC_NETCDF_CONVERTER_LIMITS_CPU=128m
PODAAC_NETCDF_CONVERTER_LIMITS_MEMORY=512Mi

QUERY_CMR_IMAGE=harmonyservices/query-cmr:stable
QUERY_CMR_REQUESTS_CPU=128m
QUERY_CMR_REQUESTS_MEMORY=128Mi
QUERY_CMR_LIMITS_CPU=128m
QUERY_CMR_LIMITS_MEMORY=512Mi

GIOVANNI_TIME_SERIES_ADAPTER_IMAGE=giovanni-time-series-adapter:1.0.0
GIOVANNI_TIME_SERIES_ADAPTER_REQUESTS_CPU=128m
GIOVANNI_TIME_SERIES_ADAPTER_REQUESTS_MEMORY=128Mi
GIOVANNI_TIME_SERIES_ADAPTER_LIMITS_CPU=128m
GIOVANNI_TIME_SERIES_ADAPTER_LIMITS_MEMORY=512Mi
GIOVANNI_TIME_SERIES_ADAPTER_INVOCATION_ARGS='python3 -m giovanni_time_series_adapter'

GIOVANNI_AVERAGING_SERVICES_ADAPTER_IMAGE=giovanni-averaging-adapter:1.0.0
GIOVANNI_AVERAGING_SERVICES_ADAPTER_REQUESTS_CPU=128m
GIOVANNI_AVERAGING_SERVICES_ADAPTER_REQUESTS_MEMORY=128Mi
GIOVANNI_AVERAGING_SERVICES_ADAPTER_LIMITS_CPU=2048m
GIOVANNI_AVERAGING_SERVICES_ADAPTER_LIMITS_MEMORY=8Gi
GIOVANNI_AVERAGING_SERVICES_ADAPTER_INVOCATION_ARGS='python3 -m giovanni_averaging_adapter'

GEOLOCO_IMAGE=ldds/geoloco:latest
GEOLOCO_REQUESTS_CPU=128m
GEOLOCO_REQUESTS_MEMORY=128Mi
GEOLOCO_LIMITS_CPU=2048m
GEOLOCO_LIMITS_MEMORY=2048Mi
GEOLOCO_INVOCATION_ARGS='python harmony_python_interface/adapter.py'
GEOLOCO_SERVICE_QUEUE_URLS='["ldds/geoloco:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/geoloco.fifo"]'

SUBSET_BAND_NAME_IMAGE=ldds/subset-band-name:latest
SUBSET_BAND_NAME_REQUESTS_CPU=128m
SUBSET_BAND_NAME_REQUESTS_MEMORY=128Mi
SUBSET_BAND_NAME_LIMITS_CPU=2048m
SUBSET_BAND_NAME_LIMITS_MEMORY=2048Mi
SUBSET_BAND_NAME_INVOCATION_ARGS='python3 /app/harmony_python_interface/adapter.py'
SUBSET_BAND_NAME_SERVICE_QUEUE_URLS='["ldds/subset-band-name:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/subset-band-name.fifo"]'

BATCHEE_IMAGE=ghcr.io/nasa/batchee:latest
BATCHEE_REQUESTS_MEMORY=128Mi
BATCHEE_LIMITS_MEMORY=512Mi
BATCHEE_INVOCATION_ARGS='./docker-entrypoint.sh'

STITCHEE_IMAGE=ghcr.io/nasa/stitchee:latest
STITCHEE_REQUESTS_CPU=128m
STITCHEE_LIMITS_CPU=128m
STITCHEE_REQUESTS_MEMORY=128Mi
STITCHEE_LIMITS_MEMORY=10Gi
STITCHEE_INVOCATION_ARGS='./docker-entrypoint.sh'

NET2COG_IMAGE=ghcr.io/podaac/net2cog:SIT
NET2COG_REQUESTS_CPU=128m
NET2COG_REQUESTS_MEMORY=128Mi
NET2COG_LIMITS_CPU=128m
NET2COG_LIMITS_MEMORY=8Gi
NET2COG_INVOCATION_ARGS='./docker-entrypoint.sh'
NET2COG_QUEUE_URLS='["ghcr.io/podaac/net2cog:SIT,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/net2cog.fifo"]'

OPERA_RTC_S1_BROWSE_IMAGE=ghcr.io/asfhyp3/opera-rtc-s1-browse:latest
OPERA_RTC_S1_BROWSE_REQUESTS_MEMORY=512Mi
OPERA_RTC_S1_BROWSE_LIMITS_MEMORY=2Gi
OPERA_RTC_S1_BROWSE_INVOCATION_ARGS='/usr/local/bin/_entrypoint.sh python -m opera_rtc_s1_browse.harmony_service'
OPERA_RTC_S1_BROWSE_SERVICE_QUEUE_URLS='["ghcr.io/asfhyp3/opera-rtc-s1-browse:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/opera-rtc-s1-browse.fifo"]'

HARMONY_SMAP_L2_GRIDDER_IMAGE=ghcr.io/nasa/harmony-smap-l2-gridder:latest
HARMONY_SMAP_L2_GRIDDER_REQUESTS_MEMORY=128Mi
HARMONY_SMAP_L2_GRIDDER_LIMITS_MEMORY=8Gi
HARMONY_SMAP_L2_GRIDDER_INVOCATION_ARGS='python -m harmony_service'
HARMONY_SMAP_L2_GRIDDER_SERVICE_QUEUE_URLS='["ghcr.io/nasa/harmony-smap-l2-gridder:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/harmony-smap-l2-gridder.fifo"]'

FILTERING_IMAGE=harmony/filtering:latest
FILTERING_REQUESTS_MEMORY=4Gi
FILTERING_LIMITS_MEMORY=6Gi
FILTERING_INVOCATION_ARGS='./docker-entrypoint.sh'
FILTERING_SERVICE_QUEUE_URLS='["harmony/filtering:latest,http://sqs.us-west-2.localhost.localstack.cloud:4566/000000000000/filtering.fifo"]'

HARMONY_METADATA_ANNOTATOR_IMAGE=ghcr.io/nasa/harmony-metadata-annotator:latest
HARMONY_METADATA_ANNOTATOR_REQUESTS_MEMORY=128Mi
HARMONY_METADATA_ANNOTATOR_LIMITS_MEMORY=8Gi
HARMONY_METADATA_ANNOTATOR_INVOCATION_ARGS='python -m harmony_service'
